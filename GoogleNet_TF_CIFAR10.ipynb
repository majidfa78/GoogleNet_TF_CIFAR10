{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, datasets"
      ],
      "metadata": {
        "id": "QiQrHPxNpEpf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"Running on GPU\")\n",
        "else:\n",
        "    print(\"GPU not available, running on CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iWky-onq4DV",
        "outputId": "2072511e-c378-44ac-ddf0-845a171d9b26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inception block equivalent in TensorFlow\n",
        "class InceptionBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_pool):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "        self.branch1 = layers.Conv2D(out_1x1, kernel_size=1, activation='relu')\n",
        "\n",
        "        self.branch2 = tf.keras.Sequential([\n",
        "            layers.Conv2D(red_3x3, kernel_size=1, activation='relu'),\n",
        "            layers.Conv2D(out_3x3, kernel_size=3, padding='same', activation='relu')\n",
        "        ])\n",
        "\n",
        "        self.branch3 = tf.keras.Sequential([\n",
        "            layers.Conv2D(red_5x5, kernel_size=1, activation='relu'),\n",
        "            layers.Conv2D(out_5x5, kernel_size=5, padding='same', activation='relu')\n",
        "        ])\n",
        "\n",
        "        self.branch4 = tf.keras.Sequential([\n",
        "            layers.MaxPool2D(pool_size=3, strides=1, padding='same'),\n",
        "            layers.Conv2D(out_pool, kernel_size=1, activation='relu')\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "        return tf.concat([branch1, branch2, branch3, branch4], axis=-1)\n"
      ],
      "metadata": {
        "id": "btBki834pG9F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# GoogleNet model in TensorFlow\n",
        "class GoogleNet(Model):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(GoogleNet, self).__init__()\n",
        "\n",
        "        self.conv1 = layers.Conv2D(64, kernel_size=7, strides=2, padding='same', activation='relu')\n",
        "        self.maxpool1 = layers.MaxPool2D(pool_size=3, strides=2, padding='same')\n",
        "        self.conv2 = layers.Conv2D(64, kernel_size=1, activation='relu')\n",
        "        self.conv3 = layers.Conv2D(192, kernel_size=3, padding='same', activation='relu')\n",
        "        self.maxpool2 = layers.MaxPool2D(pool_size=3, strides=2, padding='same')\n",
        "\n",
        "        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool3 = layers.MaxPool2D(pool_size=3, strides=2, padding='same')\n",
        "\n",
        "        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool4 = layers.MaxPool2D(pool_size=3, strides=2, padding='same')\n",
        "\n",
        "        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        self.avgpool = layers.GlobalAveragePooling2D()\n",
        "        self.dropout = layers.Dropout(0.4)\n",
        "        self.fc = layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.inception4a(x)\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "YtTTsip6pKvO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading and preprocessing for CIFAR-10\n",
        "def preprocess_data(x, y):\n",
        "    x = tf.image.resize(x, (112, 112))  # Resize to match model's expected input size\n",
        "    x = tf.image.per_image_standardization(x)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "Kzk7_9dUpQMd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "da1hBCiqpSP9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (val_images, val_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.map(preprocess_data).batch(batch_size).shuffle(10000)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.map(preprocess_data).batch(batch_size)"
      ],
      "metadata": {
        "id": "Vg6C7pNypyDn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and compile the model\n",
        "model = GoogleNet(num_classes=10)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jg2eq_XRqO0j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s96WuhJVo2Eu",
        "outputId": "54dcd9b4-7f50-4b49-da0e-7f8bc919dfb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 162ms/step - accuracy: 0.2144 - loss: 2.0273 - val_accuracy: 0.4299 - val_loss: 1.5082\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 98ms/step - accuracy: 0.4874 - loss: 1.3875 - val_accuracy: 0.5979 - val_loss: 1.1204\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 77ms/step - accuracy: 0.6253 - loss: 1.0500 - val_accuracy: 0.6696 - val_loss: 0.9332\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 81ms/step - accuracy: 0.6913 - loss: 0.8633 - val_accuracy: 0.6836 - val_loss: 0.9193\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 78ms/step - accuracy: 0.7422 - loss: 0.7368 - val_accuracy: 0.7224 - val_loss: 0.8089\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 78ms/step - accuracy: 0.7765 - loss: 0.6446 - val_accuracy: 0.7435 - val_loss: 0.7516\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 80ms/step - accuracy: 0.7981 - loss: 0.5831 - val_accuracy: 0.7468 - val_loss: 0.7649\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 81ms/step - accuracy: 0.8217 - loss: 0.5124 - val_accuracy: 0.7487 - val_loss: 0.7829\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 82ms/step - accuracy: 0.8368 - loss: 0.4759 - val_accuracy: 0.7442 - val_loss: 0.7869\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 79ms/step - accuracy: 0.8516 - loss: 0.4273 - val_accuracy: 0.7564 - val_loss: 0.7441\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78ea43c15db0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Model training\n",
        "model.fit(train_dataset, validation_data=val_dataset, epochs=epochs)\n"
      ]
    }
  ]
}